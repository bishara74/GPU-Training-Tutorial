{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOCrEuvL2BHb3KX9MWDVnpa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bishara74/GPU-Training-Tutorial/blob/main/GPU_vs_CPU_Benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial: How to Accelerate PyTorch Model Training with a GPU\n",
        "\n",
        "In this notebook, we will train a simple Convolutional Neural Network (CNN) to classify sneaker images.\n",
        "\n",
        "We will first train it on the **CPU** and time it. Then, we will train the *exact same model* on a **GPU** to see the performance difference.\n",
        "\n",
        "This project demonstrates the basics of:\n",
        "* Loading image data in PyTorch\n",
        "* Building a simple CNN\n",
        "* Writing a training loop\n",
        "* **GPU Resource Handling** to accelerate training"
      ],
      "metadata": {
        "id": "mYm3vswFDq8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_file_name = 'sneakers.zip'\n",
        "data_dir = 'sneakers_data'\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "    print(f\"'{data_dir}' folder not found. Extracting {zip_file_name}...\")\n",
        "    with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "        zip_ref.extractall(data_dir)\n",
        "    print(f\"Data extracted to '{data_dir}'\")\n",
        "else:\n",
        "    print(f\"Data directory '{data_dir}' already exists.\")\n",
        "\n",
        "\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "image_dataset_dir = os.path.join(data_dir, 'sneakers_dataset')\n",
        "\n",
        "image_dataset = datasets.ImageFolder(image_dataset_dir, transform=data_transform)\n",
        "dataloader = DataLoader(image_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "class_names = image_dataset.classes\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(f\"\\nSuccessfully loaded {len(image_dataset)} images.\")\n",
        "print(f\"Found {num_classes} classes: {class_names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYwa9lXTDxtF",
        "outputId": "24bca166-8033-48ca-b85b-8d1a48d5e346"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'sneakers_data' folder not found. Extracting sneakers.zip...\n",
            "Data extracted to 'sneakers_data'\n",
            "\n",
            "Successfully loaded 2207 images.\n",
            "Found 4 classes: ['Nike Air Force 1', 'Nike Air Jordan 1 High', 'Nike Air Max 1', 'Nike Dunk Low']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Training on the CPU ⏱️\n",
        "\n",
        "Now, we'll build our model. We'll use a famous pre-trained model called **ResNet-18** because it's strong and trains fast.\n",
        "\n",
        "To create our benchmark, we will **force** PyTorch to only use the CPU:\n",
        "1.  We define our device as `\"cpu\"`.\n",
        "2.  We send the `model` to the `device`.\n",
        "3.  In our training loop, we send every *batch* of data to the `device`.\n",
        "\n",
        "We will use `time.time()` to measure exactly how long the training takes."
      ],
      "metadata": {
        "id": "SjWAVEQNKVXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Set up\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "model = model.to(device)\n",
        "print(f\"--- Starting training on {device} ---\")\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(\"-\" * 10)\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "end_time = time.time()\n",
        "cpu_time = end_time - start_time\n",
        "\n",
        "print(\"\\n--- Training Finished ---\")\n",
        "print(f\"Total CPU Training Time: {cpu_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaRW4J3IKYsD",
        "outputId": "bcb8053e-2afe-4327-99c3-298fa6f130b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 128MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting training on cpu ---\n",
            "Epoch 1/3\n",
            "----------\n",
            "Epoch 2/3\n",
            "----------\n",
            "Epoch 3/3\n",
            "----------\n",
            "\n",
            "--- Training Finished ---\n",
            "Total CPU Training Time: 1425.24 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Training on the GPU\n",
        "Now, we will do the *exact same training*, but we'll tell PyTorch to use the GPU. The key steps are:\n",
        "1.  Check if a **\"cuda\" (NVIDIA GPU)** device is available.\n",
        "2.  Move the `model` to the `device`.\n",
        "3.  Inside the training loop, move our `inputs` and `labels` to the `device` on every batch.\n",
        "\n",
        "This is the core of **GPU resource handling**."
      ],
      "metadata": {
        "id": "7ZFSxJsHQjv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  SET UP THE GPU DEVICE\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"--- GPU is available! Starting training on {device} ---\")\n",
        "else:\n",
        "    # This is a fallback in case the GPU is not connected\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(f\"--- GPU not found, falling back to {device} ---\")\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(\"-\" * 10)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "end_time = time.time()\n",
        "gpu_time = end_time - start_time\n",
        "\n",
        "print(\"\\n--- Training Finished ---\")\n",
        "print(f\"Total GPU Training Time: {gpu_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GytSHBZ6Qvy6",
        "outputId": "d1e33253-fbec-4332-a829-9569dc09c6b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- GPU is available! Starting training on cuda ---\n",
            "Epoch 1/3\n",
            "----------\n",
            "Epoch 2/3\n",
            "----------\n",
            "Epoch 3/3\n",
            "----------\n",
            "\n",
            "--- Training Finished ---\n",
            "Total GPU Training Time: 107.13 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion: The Power of GPU Acceleration\n",
        "\n",
        "Let's compare our final results:\n",
        "\n",
        "* **Total CPU Training Time:** 1425.24 seconds (~23.7 minutes)\n",
        "* **Total GPU Training Time:** 107.13 seconds (~1.8 minutes)\n",
        "\n",
        "**Result:** By properly handling our GPU resources, we achieved a **13.3x speedup!**\n",
        "\n",
        "This notebook is now a **shared resource** and **tutorial** for any developer looking to get started with GPU-accelerated deep learning."
      ],
      "metadata": {
        "id": "E1ohywaNRvEK"
      }
    }
  ]
}